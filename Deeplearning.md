
# Percented于寒假期间四川农业大学深度视觉农业实验室的作业

## 任务一： 
在安装 PyTorch 之前，我首先检查了本机的硬件环境，重点关注我的电脑具备可用于深度学习加速的NVIDIA显卡。 
通过nvidia-smi命令确认本机存在NVIDIA-GPU，并且显卡驱动已正确安装，支持CUDA计算。 
随后，我查阅了 PyTorch 官方网站提供的安装指南，对比了CPU版本与CUDA版本的区别。CPU版本仅使用处理器进行计算，而CUDA版本可以利用GPU进行并行加速，在模型训练和大规模矩阵运算中具有显著的性能优势。 
结合本机硬件条件以及后续可能涉及深度学习模型训练的需求，我最终选择安装 支持CUDA的PyTorch版本，以充分利用GPU的计算能力，提高运行效率。

在安装Anaconda及PyTorch相关依赖的过程中，我遇到了由于网络不稳定导致的安装问题，主要表现为下载速度过慢、连接超时或依赖包无法正常获取。 
针对该问题，我首先判断这并非配置或命令本身的错误，而是由网络环境限制造成的。随后通过多次切换网络环境，并使用网络代理工具改善网络连接质量，确保能够正常访问官方软件源和镜像站点。 
在网络条件稳定后，相关依赖包得以顺利下载并完成安装，环境配置问题得到解决。通过此次排错过程，我也加深了对软件安装过程中常见问题及其解决思路的理解。

## 任务二：
在完成一元非线性回归任务前，我首先进行了数据的加载与预处理工作。本次任务使用的数据集包含单一自变量x与因变量 y，我先通过pandas读取csv格式的数据集，将x与y的数值转换为浮点型数组，并调整其维度以匹配模型的输入要求，随后将数组转换为PyTorch张量，为后续模型训练做准备。
接着，我手动构建了MLP模型以拟合数据的非线性关系。该模型包含输入层、两层隐藏层与输出层：输入层接收维度为1的特征，经64维隐藏层与ReLU激活函数、32维隐藏层与ReLU激活函数的特征转换后，由输出层输出预测的y值。这样的结构能够捕捉数据中复杂的非线性关联。
随后我完成了模型的训练配置与训练过程。选择MSE作为回归任务的损失函数，使用Adam进行参数更新 并将初始学习率设为 0.001，并设置训练轮次为1000次。训练过程中，我持续记录损失值的变化，并保存了第10、100、1000轮次的预测结果，以便后续对比不同训练阶段的拟合效果。
训练完成后，我开展了可视化分析工作：一方面绘制了不同训练轮次下模型的拟合曲线与真实数据的对比图，观察模型对非线性关系的拟合程度；另一方面，我通过训练不同学习率（过大的——1.0、过小的——0.00001、正常的——0.001）的模型，绘制损失曲线对比图，分析学习率对训练过程的影响。
在实验过程中，我遇到了学习率设置不合理导致的训练问题：学习率过大时，损失值持续震荡无法收敛；学习率过小时，损失值下降极其缓慢，难以达到理想的拟合效果。针对这一问题，我通过对比不同学习率的损失曲线，明确了合适学习率的选择标准，最终确定 0.001 为本次任务的最优学习率。
##### 关于遇到的问题
在编写 #4 模型训练 的过程中，我在编写时依赖了VSCode的自动补全功能快速输入语句，但初期因自动补全未提示张量类型转换规则，忽略了PyTorch张量需先脱离计算图、再转换为numpy数组”的要求。
###### 1.解决过程：
搜索关键词：TypeError: 'float'object is not subscriptable Cell Execution Error；
未询问AI，通过搜索结果定位到问题根源：带梯度的张量无法直接转numpy数组；
解决方案：在numpy()前添加detach()，即y_pred.detach().numpy()，让张量脱离计算图后再转换格式。
###### 2. AI 使用说明
AI 最有用的环节：在绘图环节帮助最大——我不熟悉Matplotlib 多子图、曲线排序等可视化细节，AI直接生成了 “不同 epoch 拟合曲线对比”“学习率 Loss 曲线对比” 的完整代码，帮我快速完成了结果可视化。
AI 未失效的环节：本次任务中 AI 未出现失效情况，无论是解释detach()概念还是编写模型代码，都准确匹配了 PyTorch 的最新 API 与任务需求。
如果没有AI，我能独立完成的部分包括：
数据读取与预处理（熟悉pandas、NumPy的格式转换）；
MLP 模型搭建（因有MNIST手写识别的学习经历，能独立完成线性层、激活函数的堆叠）；
模型训练流程（掌握优化器、损失函数、前向/反向传播的基础逻辑）。

通过本次任务，我不仅掌握了MLP模型构建与训练的流程，还深入理解了学习率对模型训练的关键影响，同时熟悉了回归任务中拟合效果与损失曲线的可视化方法，为后续更复杂的深度学习任务积累了实践经验。